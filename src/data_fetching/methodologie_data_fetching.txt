# Collecte des DonnÃ©es S&P 500

## ğŸ¯ Objectif
RÃ©cupÃ©ration automatique de la composition actuelle du S&P 500 et tÃ©lÃ©chargement des prix OHLCV pour tous les tickers.

## âš¡ Pipeline en 4 Ã©tapes

1. **ğŸ“‹ Liste des tickers** : Scraping Wikipedia â†’ `sp500_tickers.csv`
2. **ğŸ“¥ TÃ©lÃ©chargement parallÃ¨le** : Yahoo Finance (10 ans par dÃ©faut, retry automatique)
3. **ğŸ§¹ Nettoyage** : Standardisation, validation, suppression des donnÃ©es invalides
4. **ğŸ’¾ Consolidation** : Dataset multi-ticker â†’ `dataset.csv/parquet`

## ğŸ—ï¸ Architecture
- **ParallÃ©lisation** : ThreadPoolExecutor pour rapiditÃ©
- **Robustesse** : Gestion d'erreurs, continuation malgrÃ© les Ã©checs
- **QualitÃ©** : Validation automatique, logs dÃ©taillÃ©s

## ğŸ“ Modules clÃ©s
- `wikipedia.py` : Parsing tickers
- `download.py` : TÃ©lÃ©chargement parallÃ¨le
- `processing.py` : Nettoyage donnÃ©es
- `reporting.py` : Consolidation finale

## âš ï¸ Points critiques
- Composition S&P 500 Ã©volue rÃ©guliÃ¨rement
- Gestion des tickers delistÃ©s
- Respect des limites API Yahoo Finance
- Alignement temporel entre tickers

## âœ… RÃ©sultat
Dataset prÃªt pour analyse : 500+ tickers, prix quotidiens, donnÃ©es validÃ©es.
