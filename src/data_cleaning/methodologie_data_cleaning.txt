# Nettoyage des DonnÃ©es S&P 500

## ğŸ¯ Mission
Transformer les donnÃ©es brutes de Yahoo Finance en dataset propre et fiable, **sans perdre d'informations**. PrÃªt pour l'analyse et le ML.

## âš¡ Pipeline en 3 Ã©tapes

### 1. Validation des donnÃ©es brutes
- **EntrÃ©e** : `data/dataset.csv`
- **VÃ©rifications** : colonnes requises (`date`, `tickers`, `open`, `close`, `volume`)
- **Normalisation** : dates converties en timezone America/New_York, normalisÃ©es Ã  minuit

### 2. Corrections d'intÃ©gritÃ©
- **Doublons** : suppression automatique sur paires `(date, ticker)`
- **Valeurs manquantes** : remplissage avec 0 pour `open`, `close`, `volume`
- **Tri** : par ticker puis date pour stabilitÃ©

### 3. Sauvegarde dual-format
- **Sortie** : `data/dataset_filtered.csv` + `data/dataset_filtered.parquet`
- **Logging** : compteurs des corrections appliquÃ©es

## ğŸ—ï¸ Architecture

### Fonction principale
```bash
python -m src.data_cleaning.main  # ou filter_by_membership()
```

### Modules actifs
- `validation.py` : contrÃ´les et conversions
- `integrity.py` : corrections automatiques
- `filtering.py` : sauvegarde CSV/Parquet
- `data_cleaning.py` : orchestration

## âœ… Garanties
- **ZÃ©ro perte de donnÃ©es** : aucun ticker supprimÃ©
- **Robustesse** : Ã©chec explicite sur donnÃ©es invalides
- **TraÃ§abilitÃ©** : logs dÃ©taillÃ©s de chaque correction
- **TestabilitÃ©** : chemins configurables via `constants.py`

## ğŸ§ª Tests
- Unitaires : validation, intÃ©gritÃ©, dates
- IntÃ©gration : Ã©criture disque, CLI
- Mocks/fixtures : isolation complÃ¨te
